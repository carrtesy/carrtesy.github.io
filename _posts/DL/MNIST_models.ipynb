{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWfUwpf4WX7s"
      },
      "source": [
        "We have implemented base models for MNIST with keras. How can we implement more sophisticated version?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIYEpgWdWda7"
      },
      "source": [
        "## Setups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNaoETX0Wio9"
      },
      "source": [
        "what we need is tensorflow, keras mainly, and a bit of other libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05e8s24MAu49"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDDIPJ4SWt7Q"
      },
      "source": [
        "Check if gpu is available here. Are we good?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90WDZqhBLkIL",
        "outputId": "2e5921ad-2030-4213-d1c4-82fa27dd97d8"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNdmSshNXY_N"
      },
      "source": [
        "## Load Data, EDA, and preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqDhx4qSBH2a"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dmQ3S8KJMqz"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh1rvfCaBNm9",
        "outputId": "2890d4f9-99c2-4af8-9f9e-34de2ad2127a"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((54000, 28, 28), (54000,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dna_wLdJ0uP",
        "outputId": "1d984a92-b7a2-4446-e850-75d26ec24a7e"
      },
      "source": [
        "x_val.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6000, 28, 28), (6000,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyBe7JwyBPXJ",
        "outputId": "a0f3b865-0f43-477b-d8d6-3cd660b19e2a"
      },
      "source": [
        "x_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNv0O0qjBSPW"
      },
      "source": [
        "x_train, x_val, x_test = x_train / 255.0, x_val / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_6UgVIyEuCD"
      },
      "source": [
        "y_train, y_val, y_test = tf.keras.utils.to_categorical(y_train), tf.keras.utils.to_categorical(y_val), tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoVX-h96E4HW",
        "outputId": "dd8885ac-0c98-4ca2-af27-1e66d22fab6f"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "H7b9B0NjByMw",
        "outputId": "effff5e1-0ab7-4981-8693-e46989ea452b"
      },
      "source": [
        "for i in range(6):\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(x_train[i], cmap = \"gray\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K39jIoafCBE6"
      },
      "source": [
        "## Models\n",
        "\n",
        "Let's set up some hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-yZ-nq4B8lR"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "loss = keras.losses.CategoricalCrossentropy()\n",
        "metrics = [\"accuracy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oVscyCrBcxs"
      },
      "source": [
        "optimizer = keras.optimizers.SGD(learning_rate = 1e-03)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPbVHWg0A0Za"
      },
      "source": [
        "### MLP\n",
        "\n",
        "Our first apporoach is Multi-layer Perceptron (MLP).\n",
        "\n",
        "MLP introduces hidden layer with non-linear activation functions.\n",
        "\n",
        "This combination can generate universal approximator. That is, theortically it can approximate every functions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3IAZmEvAzhP"
      },
      "source": [
        "MLL_model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape = (28, 28)),\n",
        "    keras.layers.Dense(256, activation = \"sigmoid\"),\n",
        "    keras.layers.Dense(128, activation = \"sigmoid\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\"),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJsUL4DAA-On",
        "outputId": "7fe63e98-fa6c-4914-df4d-234318c075d0"
      },
      "source": [
        "MLL_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               200960    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrRRexBpaTzz"
      },
      "source": [
        "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"./best.ckpt\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNi_E_8Cp6_1"
      },
      "source": [
        "MLL_model.compile(loss = loss, optimizer = optimizer, metrics = metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(device_name = device_name):\n",
        "    hist = MLL_model.fit(x_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, shuffle = True, verbose = 2, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrE-4NmR-G1d",
        "outputId": "8b9d9834-3553-4b71-fb40-10cf8e2d9e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "844/844 - 9s - loss: 2.3369 - accuracy: 0.0925 - val_loss: 2.2991 - val_accuracy: 0.1048 - 9s/epoch - 10ms/step\n",
            "Epoch 2/100\n",
            "844/844 - 6s - loss: 2.2931 - accuracy: 0.1090 - val_loss: 2.2884 - val_accuracy: 0.1097 - 6s/epoch - 7ms/step\n",
            "Epoch 3/100\n",
            "844/844 - 4s - loss: 2.2823 - accuracy: 0.1243 - val_loss: 2.2775 - val_accuracy: 0.1630 - 4s/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "844/844 - 4s - loss: 2.2715 - accuracy: 0.1570 - val_loss: 2.2667 - val_accuracy: 0.2445 - 4s/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "844/844 - 3s - loss: 2.2606 - accuracy: 0.2233 - val_loss: 2.2560 - val_accuracy: 0.2190 - 3s/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "844/844 - 3s - loss: 2.2493 - accuracy: 0.2343 - val_loss: 2.2444 - val_accuracy: 0.3153 - 3s/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "844/844 - 3s - loss: 2.2378 - accuracy: 0.3005 - val_loss: 2.2327 - val_accuracy: 0.3302 - 3s/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "844/844 - 3s - loss: 2.2257 - accuracy: 0.3408 - val_loss: 2.2205 - val_accuracy: 0.3440 - 3s/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "844/844 - 3s - loss: 2.2132 - accuracy: 0.3778 - val_loss: 2.2081 - val_accuracy: 0.3505 - 3s/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "844/844 - 3s - loss: 2.2000 - accuracy: 0.4132 - val_loss: 2.1943 - val_accuracy: 0.3742 - 3s/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "844/844 - 3s - loss: 2.1861 - accuracy: 0.4260 - val_loss: 2.1797 - val_accuracy: 0.4393 - 3s/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "844/844 - 3s - loss: 2.1714 - accuracy: 0.4606 - val_loss: 2.1649 - val_accuracy: 0.4605 - 3s/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "844/844 - 3s - loss: 2.1557 - accuracy: 0.4830 - val_loss: 2.1487 - val_accuracy: 0.4720 - 3s/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "844/844 - 3s - loss: 2.1390 - accuracy: 0.4947 - val_loss: 2.1313 - val_accuracy: 0.5175 - 3s/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "844/844 - 3s - loss: 2.1212 - accuracy: 0.5257 - val_loss: 2.1130 - val_accuracy: 0.5203 - 3s/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "844/844 - 3s - loss: 2.1020 - accuracy: 0.5338 - val_loss: 2.0932 - val_accuracy: 0.5415 - 3s/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "844/844 - 3s - loss: 2.0816 - accuracy: 0.5467 - val_loss: 2.0723 - val_accuracy: 0.5558 - 3s/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "844/844 - 3s - loss: 2.0596 - accuracy: 0.5677 - val_loss: 2.0497 - val_accuracy: 0.5447 - 3s/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "844/844 - 3s - loss: 2.0362 - accuracy: 0.5698 - val_loss: 2.0254 - val_accuracy: 0.5683 - 3s/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "844/844 - 3s - loss: 2.0111 - accuracy: 0.5799 - val_loss: 1.9992 - val_accuracy: 0.5787 - 3s/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "844/844 - 3s - loss: 1.9843 - accuracy: 0.5916 - val_loss: 1.9718 - val_accuracy: 0.5877 - 3s/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "844/844 - 3s - loss: 1.9559 - accuracy: 0.6020 - val_loss: 1.9427 - val_accuracy: 0.5838 - 3s/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "844/844 - 3s - loss: 1.9257 - accuracy: 0.6031 - val_loss: 1.9118 - val_accuracy: 0.6095 - 3s/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "844/844 - 3s - loss: 1.8940 - accuracy: 0.6161 - val_loss: 1.8794 - val_accuracy: 0.6117 - 3s/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "844/844 - 3s - loss: 1.8606 - accuracy: 0.6199 - val_loss: 1.8453 - val_accuracy: 0.6340 - 3s/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "844/844 - 3s - loss: 1.8258 - accuracy: 0.6311 - val_loss: 1.8098 - val_accuracy: 0.6388 - 3s/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "844/844 - 3s - loss: 1.7897 - accuracy: 0.6401 - val_loss: 1.7733 - val_accuracy: 0.6432 - 3s/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "844/844 - 3s - loss: 1.7525 - accuracy: 0.6464 - val_loss: 1.7356 - val_accuracy: 0.6537 - 3s/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "844/844 - 3s - loss: 1.7145 - accuracy: 0.6535 - val_loss: 1.6974 - val_accuracy: 0.6633 - 3s/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "844/844 - 3s - loss: 1.6759 - accuracy: 0.6620 - val_loss: 1.6587 - val_accuracy: 0.6727 - 3s/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "844/844 - 3s - loss: 1.6369 - accuracy: 0.6706 - val_loss: 1.6199 - val_accuracy: 0.6757 - 3s/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "844/844 - 3s - loss: 1.5980 - accuracy: 0.6787 - val_loss: 1.5808 - val_accuracy: 0.6833 - 3s/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "844/844 - 3s - loss: 1.5591 - accuracy: 0.6851 - val_loss: 1.5423 - val_accuracy: 0.6877 - 3s/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "844/844 - 3s - loss: 1.5207 - accuracy: 0.6904 - val_loss: 1.5041 - val_accuracy: 0.7037 - 3s/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "844/844 - 3s - loss: 1.4829 - accuracy: 0.7022 - val_loss: 1.4666 - val_accuracy: 0.7027 - 3s/epoch - 4ms/step\n",
            "Epoch 36/100\n",
            "844/844 - 3s - loss: 1.4458 - accuracy: 0.7073 - val_loss: 1.4300 - val_accuracy: 0.7088 - 3s/epoch - 4ms/step\n",
            "Epoch 37/100\n",
            "844/844 - 3s - loss: 1.4096 - accuracy: 0.7152 - val_loss: 1.3942 - val_accuracy: 0.7120 - 3s/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "844/844 - 3s - loss: 1.3743 - accuracy: 0.7179 - val_loss: 1.3594 - val_accuracy: 0.7253 - 3s/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "844/844 - 3s - loss: 1.3401 - accuracy: 0.7266 - val_loss: 1.3258 - val_accuracy: 0.7272 - 3s/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "844/844 - 3s - loss: 1.3070 - accuracy: 0.7302 - val_loss: 1.2930 - val_accuracy: 0.7392 - 3s/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "844/844 - 3s - loss: 1.2749 - accuracy: 0.7368 - val_loss: 1.2617 - val_accuracy: 0.7397 - 3s/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "844/844 - 3s - loss: 1.2440 - accuracy: 0.7416 - val_loss: 1.2311 - val_accuracy: 0.7497 - 3s/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "844/844 - 3s - loss: 1.2142 - accuracy: 0.7470 - val_loss: 1.2017 - val_accuracy: 0.7510 - 3s/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "844/844 - 3s - loss: 1.1855 - accuracy: 0.7529 - val_loss: 1.1735 - val_accuracy: 0.7533 - 3s/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "844/844 - 3s - loss: 1.1579 - accuracy: 0.7559 - val_loss: 1.1461 - val_accuracy: 0.7625 - 3s/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "844/844 - 3s - loss: 1.1314 - accuracy: 0.7596 - val_loss: 1.1201 - val_accuracy: 0.7702 - 3s/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "844/844 - 3s - loss: 1.1059 - accuracy: 0.7656 - val_loss: 1.0949 - val_accuracy: 0.7710 - 3s/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "844/844 - 3s - loss: 1.0815 - accuracy: 0.7696 - val_loss: 1.0708 - val_accuracy: 0.7738 - 3s/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "844/844 - 3s - loss: 1.0580 - accuracy: 0.7727 - val_loss: 1.0476 - val_accuracy: 0.7792 - 3s/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "844/844 - 3s - loss: 1.0355 - accuracy: 0.7764 - val_loss: 1.0255 - val_accuracy: 0.7833 - 3s/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "844/844 - 3s - loss: 1.0139 - accuracy: 0.7794 - val_loss: 1.0043 - val_accuracy: 0.7870 - 3s/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "844/844 - 3s - loss: 0.9933 - accuracy: 0.7833 - val_loss: 0.9840 - val_accuracy: 0.7905 - 3s/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "844/844 - 3s - loss: 0.9735 - accuracy: 0.7863 - val_loss: 0.9643 - val_accuracy: 0.7925 - 3s/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "844/844 - 3s - loss: 0.9544 - accuracy: 0.7909 - val_loss: 0.9457 - val_accuracy: 0.7942 - 3s/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "844/844 - 3s - loss: 0.9363 - accuracy: 0.7922 - val_loss: 0.9276 - val_accuracy: 0.7998 - 3s/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "844/844 - 3s - loss: 0.9188 - accuracy: 0.7962 - val_loss: 0.9103 - val_accuracy: 0.8005 - 3s/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "844/844 - 3s - loss: 0.9021 - accuracy: 0.7981 - val_loss: 0.8938 - val_accuracy: 0.8040 - 3s/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "844/844 - 3s - loss: 0.8861 - accuracy: 0.8014 - val_loss: 0.8779 - val_accuracy: 0.8063 - 3s/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "844/844 - 3s - loss: 0.8707 - accuracy: 0.8038 - val_loss: 0.8627 - val_accuracy: 0.8082 - 3s/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "844/844 - 3s - loss: 0.8559 - accuracy: 0.8063 - val_loss: 0.8482 - val_accuracy: 0.8108 - 3s/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "844/844 - 3s - loss: 0.8417 - accuracy: 0.8085 - val_loss: 0.8341 - val_accuracy: 0.8138 - 3s/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "844/844 - 3s - loss: 0.8281 - accuracy: 0.8111 - val_loss: 0.8207 - val_accuracy: 0.8147 - 3s/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "844/844 - 3s - loss: 0.8150 - accuracy: 0.8130 - val_loss: 0.8077 - val_accuracy: 0.8178 - 3s/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "844/844 - 3s - loss: 0.8024 - accuracy: 0.8154 - val_loss: 0.7953 - val_accuracy: 0.8182 - 3s/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "844/844 - 3s - loss: 0.7903 - accuracy: 0.8171 - val_loss: 0.7834 - val_accuracy: 0.8207 - 3s/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "844/844 - 3s - loss: 0.7787 - accuracy: 0.8195 - val_loss: 0.7716 - val_accuracy: 0.8222 - 3s/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "844/844 - 3s - loss: 0.7675 - accuracy: 0.8215 - val_loss: 0.7605 - val_accuracy: 0.8245 - 3s/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "844/844 - 3s - loss: 0.7567 - accuracy: 0.8229 - val_loss: 0.7498 - val_accuracy: 0.8275 - 3s/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "844/844 - 3s - loss: 0.7463 - accuracy: 0.8253 - val_loss: 0.7396 - val_accuracy: 0.8280 - 3s/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "844/844 - 3s - loss: 0.7362 - accuracy: 0.8266 - val_loss: 0.7296 - val_accuracy: 0.8305 - 3s/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "844/844 - 3s - loss: 0.7266 - accuracy: 0.8283 - val_loss: 0.7200 - val_accuracy: 0.8327 - 3s/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "844/844 - 3s - loss: 0.7172 - accuracy: 0.8292 - val_loss: 0.7108 - val_accuracy: 0.8347 - 3s/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "844/844 - 3s - loss: 0.7082 - accuracy: 0.8312 - val_loss: 0.7017 - val_accuracy: 0.8385 - 3s/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "844/844 - 3s - loss: 0.6995 - accuracy: 0.8326 - val_loss: 0.6931 - val_accuracy: 0.8385 - 3s/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "844/844 - 3s - loss: 0.6911 - accuracy: 0.8337 - val_loss: 0.6847 - val_accuracy: 0.8415 - 3s/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "844/844 - 3s - loss: 0.6830 - accuracy: 0.8353 - val_loss: 0.6767 - val_accuracy: 0.8412 - 3s/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "844/844 - 3s - loss: 0.6752 - accuracy: 0.8363 - val_loss: 0.6689 - val_accuracy: 0.8437 - 3s/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "844/844 - 3s - loss: 0.6676 - accuracy: 0.8380 - val_loss: 0.6614 - val_accuracy: 0.8442 - 3s/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "844/844 - 3s - loss: 0.6602 - accuracy: 0.8396 - val_loss: 0.6541 - val_accuracy: 0.8447 - 3s/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "844/844 - 3s - loss: 0.6531 - accuracy: 0.8407 - val_loss: 0.6470 - val_accuracy: 0.8463 - 3s/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "844/844 - 3s - loss: 0.6463 - accuracy: 0.8420 - val_loss: 0.6401 - val_accuracy: 0.8467 - 3s/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "844/844 - 3s - loss: 0.6396 - accuracy: 0.8430 - val_loss: 0.6338 - val_accuracy: 0.8462 - 3s/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "844/844 - 3s - loss: 0.6332 - accuracy: 0.8439 - val_loss: 0.6272 - val_accuracy: 0.8478 - 3s/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "844/844 - 3s - loss: 0.6269 - accuracy: 0.8454 - val_loss: 0.6209 - val_accuracy: 0.8492 - 3s/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "844/844 - 3s - loss: 0.6208 - accuracy: 0.8465 - val_loss: 0.6150 - val_accuracy: 0.8515 - 3s/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "844/844 - 3s - loss: 0.6149 - accuracy: 0.8472 - val_loss: 0.6090 - val_accuracy: 0.8520 - 3s/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "844/844 - 3s - loss: 0.6092 - accuracy: 0.8483 - val_loss: 0.6034 - val_accuracy: 0.8532 - 3s/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "844/844 - 3s - loss: 0.6036 - accuracy: 0.8496 - val_loss: 0.5979 - val_accuracy: 0.8535 - 3s/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "844/844 - 3s - loss: 0.5983 - accuracy: 0.8501 - val_loss: 0.5925 - val_accuracy: 0.8552 - 3s/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "844/844 - 3s - loss: 0.5930 - accuracy: 0.8512 - val_loss: 0.5872 - val_accuracy: 0.8557 - 3s/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "844/844 - 3s - loss: 0.5879 - accuracy: 0.8521 - val_loss: 0.5821 - val_accuracy: 0.8553 - 3s/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "844/844 - 3s - loss: 0.5830 - accuracy: 0.8532 - val_loss: 0.5771 - val_accuracy: 0.8568 - 3s/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "844/844 - 3s - loss: 0.5782 - accuracy: 0.8535 - val_loss: 0.5723 - val_accuracy: 0.8573 - 3s/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "844/844 - 3s - loss: 0.5734 - accuracy: 0.8546 - val_loss: 0.5678 - val_accuracy: 0.8583 - 3s/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "844/844 - 3s - loss: 0.5689 - accuracy: 0.8553 - val_loss: 0.5630 - val_accuracy: 0.8590 - 3s/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "844/844 - 3s - loss: 0.5645 - accuracy: 0.8561 - val_loss: 0.5587 - val_accuracy: 0.8602 - 3s/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "844/844 - 3s - loss: 0.5601 - accuracy: 0.8570 - val_loss: 0.5545 - val_accuracy: 0.8613 - 3s/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "844/844 - 3s - loss: 0.5559 - accuracy: 0.8576 - val_loss: 0.5501 - val_accuracy: 0.8627 - 3s/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "844/844 - 3s - loss: 0.5518 - accuracy: 0.8581 - val_loss: 0.5461 - val_accuracy: 0.8628 - 3s/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "844/844 - 3s - loss: 0.5478 - accuracy: 0.8586 - val_loss: 0.5421 - val_accuracy: 0.8640 - 3s/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(device_name = device_name):\n",
        "    MLL_model.evaluate(x_test, y_test, batch_size = BATCH_SIZE, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHFOAY8v-LA3",
        "outputId": "85da58b0-a39c-463a-b130-ba64bd0ecbd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 - 0s - loss: 0.5298 - accuracy: 0.8646 - 423ms/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN\n",
        "\n",
        "Convolutional neural network (CNN) performs great on most image tasks. Let's try this. "
      ],
      "metadata": {
        "id": "3vbcAOf8-YEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, x_test = np.expand_dims(x_train, -1), np.expand_dims(x_val, -1), np.expand_dims(x_test, -1)"
      ],
      "metadata": {
        "id": "NCifTPwx-XD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_val.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP4oTRFU-bIz",
        "outputId": "a36bdc28-0b9e-48df-8c17-672984effc41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((54000, 28, 28, 1), (6000, 28, 28, 1), (10000, 28, 28, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256, activation = \"relu\"),\n",
        "    keras.layers.Dense(128, activation = \"relu\"),\n",
        "    keras.layers.Dense(10, activation = \"softmax\"),\n",
        "])\n",
        "\n",
        "CNN_model.summary()\n",
        "CNN_model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
        "\n",
        "with tf.device(device_name = device_name):\n",
        "    print(\"training start!\")\n",
        "    hist = CNN_model.fit(x_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, shuffle = True, verbose = 2, validation_data=(x_val, y_val))\n",
        "    print(\"evaluation start!\")\n",
        "    CNN_model.evaluate(x_test, y_test, batch_size = BATCH_SIZE, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2a1sIly-cSi",
        "outputId": "97c8874c-0ab0-44a7-c507-58f9ed63a829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 5408)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               1384704   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,419,210\n",
            "Trainable params: 1,419,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "training start!\n",
            "Epoch 1/100\n",
            "844/844 - 12s - loss: 2.1092 - accuracy: 0.4856 - val_loss: 1.8201 - val_accuracy: 0.7348 - 12s/epoch - 14ms/step\n",
            "Epoch 2/100\n",
            "844/844 - 5s - loss: 1.2947 - accuracy: 0.7912 - val_loss: 0.8312 - val_accuracy: 0.8378 - 5s/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "844/844 - 5s - loss: 0.6397 - accuracy: 0.8520 - val_loss: 0.5152 - val_accuracy: 0.8727 - 5s/epoch - 6ms/step\n",
            "Epoch 4/100\n",
            "844/844 - 5s - loss: 0.4636 - accuracy: 0.8779 - val_loss: 0.4142 - val_accuracy: 0.8935 - 5s/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "844/844 - 5s - loss: 0.3961 - accuracy: 0.8900 - val_loss: 0.3656 - val_accuracy: 0.8995 - 5s/epoch - 6ms/step\n",
            "Epoch 6/100\n",
            "844/844 - 5s - loss: 0.3599 - accuracy: 0.8979 - val_loss: 0.3382 - val_accuracy: 0.9070 - 5s/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "844/844 - 5s - loss: 0.3363 - accuracy: 0.9034 - val_loss: 0.3166 - val_accuracy: 0.9098 - 5s/epoch - 6ms/step\n",
            "Epoch 8/100\n",
            "844/844 - 5s - loss: 0.3189 - accuracy: 0.9074 - val_loss: 0.3020 - val_accuracy: 0.9147 - 5s/epoch - 6ms/step\n",
            "Epoch 9/100\n",
            "844/844 - 5s - loss: 0.3051 - accuracy: 0.9116 - val_loss: 0.2890 - val_accuracy: 0.9157 - 5s/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "844/844 - 5s - loss: 0.2935 - accuracy: 0.9149 - val_loss: 0.2784 - val_accuracy: 0.9210 - 5s/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "844/844 - 5s - loss: 0.2830 - accuracy: 0.9180 - val_loss: 0.2696 - val_accuracy: 0.9230 - 5s/epoch - 6ms/step\n",
            "Epoch 12/100\n",
            "844/844 - 5s - loss: 0.2739 - accuracy: 0.9206 - val_loss: 0.2597 - val_accuracy: 0.9283 - 5s/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "844/844 - 5s - loss: 0.2655 - accuracy: 0.9229 - val_loss: 0.2523 - val_accuracy: 0.9283 - 5s/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "844/844 - 4s - loss: 0.2577 - accuracy: 0.9249 - val_loss: 0.2451 - val_accuracy: 0.9307 - 4s/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "844/844 - 5s - loss: 0.2503 - accuracy: 0.9279 - val_loss: 0.2372 - val_accuracy: 0.9342 - 5s/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "844/844 - 5s - loss: 0.2433 - accuracy: 0.9293 - val_loss: 0.2322 - val_accuracy: 0.9343 - 5s/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "844/844 - 4s - loss: 0.2366 - accuracy: 0.9314 - val_loss: 0.2263 - val_accuracy: 0.9372 - 4s/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "844/844 - 5s - loss: 0.2305 - accuracy: 0.9334 - val_loss: 0.2198 - val_accuracy: 0.9392 - 5s/epoch - 6ms/step\n",
            "Epoch 19/100\n",
            "844/844 - 5s - loss: 0.2246 - accuracy: 0.9346 - val_loss: 0.2149 - val_accuracy: 0.9388 - 5s/epoch - 6ms/step\n",
            "Epoch 20/100\n",
            "844/844 - 5s - loss: 0.2189 - accuracy: 0.9361 - val_loss: 0.2091 - val_accuracy: 0.9400 - 5s/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "844/844 - 5s - loss: 0.2138 - accuracy: 0.9376 - val_loss: 0.2044 - val_accuracy: 0.9423 - 5s/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "844/844 - 5s - loss: 0.2086 - accuracy: 0.9394 - val_loss: 0.2007 - val_accuracy: 0.9427 - 5s/epoch - 6ms/step\n",
            "Epoch 23/100\n",
            "844/844 - 5s - loss: 0.2036 - accuracy: 0.9409 - val_loss: 0.1956 - val_accuracy: 0.9452 - 5s/epoch - 6ms/step\n",
            "Epoch 24/100\n",
            "844/844 - 5s - loss: 0.1991 - accuracy: 0.9418 - val_loss: 0.1917 - val_accuracy: 0.9462 - 5s/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "844/844 - 5s - loss: 0.1946 - accuracy: 0.9432 - val_loss: 0.1877 - val_accuracy: 0.9463 - 5s/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "844/844 - 5s - loss: 0.1901 - accuracy: 0.9449 - val_loss: 0.1830 - val_accuracy: 0.9467 - 5s/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "844/844 - 4s - loss: 0.1861 - accuracy: 0.9454 - val_loss: 0.1814 - val_accuracy: 0.9483 - 4s/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "844/844 - 5s - loss: 0.1821 - accuracy: 0.9465 - val_loss: 0.1782 - val_accuracy: 0.9507 - 5s/epoch - 6ms/step\n",
            "Epoch 29/100\n",
            "844/844 - 5s - loss: 0.1784 - accuracy: 0.9478 - val_loss: 0.1732 - val_accuracy: 0.9515 - 5s/epoch - 6ms/step\n",
            "Epoch 30/100\n",
            "844/844 - 5s - loss: 0.1749 - accuracy: 0.9487 - val_loss: 0.1691 - val_accuracy: 0.9525 - 5s/epoch - 6ms/step\n",
            "Epoch 31/100\n",
            "844/844 - 5s - loss: 0.1712 - accuracy: 0.9499 - val_loss: 0.1657 - val_accuracy: 0.9535 - 5s/epoch - 6ms/step\n",
            "Epoch 32/100\n",
            "844/844 - 4s - loss: 0.1678 - accuracy: 0.9511 - val_loss: 0.1631 - val_accuracy: 0.9545 - 4s/epoch - 5ms/step\n",
            "Epoch 33/100\n",
            "844/844 - 5s - loss: 0.1646 - accuracy: 0.9516 - val_loss: 0.1605 - val_accuracy: 0.9553 - 5s/epoch - 5ms/step\n",
            "Epoch 34/100\n",
            "844/844 - 5s - loss: 0.1614 - accuracy: 0.9534 - val_loss: 0.1573 - val_accuracy: 0.9567 - 5s/epoch - 6ms/step\n",
            "Epoch 35/100\n",
            "844/844 - 4s - loss: 0.1584 - accuracy: 0.9537 - val_loss: 0.1559 - val_accuracy: 0.9575 - 4s/epoch - 5ms/step\n",
            "Epoch 36/100\n",
            "844/844 - 5s - loss: 0.1556 - accuracy: 0.9544 - val_loss: 0.1528 - val_accuracy: 0.9570 - 5s/epoch - 6ms/step\n",
            "Epoch 37/100\n",
            "844/844 - 5s - loss: 0.1527 - accuracy: 0.9553 - val_loss: 0.1512 - val_accuracy: 0.9587 - 5s/epoch - 6ms/step\n",
            "Epoch 38/100\n",
            "844/844 - 5s - loss: 0.1500 - accuracy: 0.9562 - val_loss: 0.1487 - val_accuracy: 0.9587 - 5s/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "844/844 - 5s - loss: 0.1472 - accuracy: 0.9572 - val_loss: 0.1460 - val_accuracy: 0.9593 - 5s/epoch - 6ms/step\n",
            "Epoch 40/100\n",
            "844/844 - 5s - loss: 0.1448 - accuracy: 0.9575 - val_loss: 0.1440 - val_accuracy: 0.9600 - 5s/epoch - 6ms/step\n",
            "Epoch 41/100\n",
            "844/844 - 5s - loss: 0.1423 - accuracy: 0.9586 - val_loss: 0.1413 - val_accuracy: 0.9600 - 5s/epoch - 6ms/step\n",
            "Epoch 42/100\n",
            "844/844 - 5s - loss: 0.1399 - accuracy: 0.9593 - val_loss: 0.1395 - val_accuracy: 0.9597 - 5s/epoch - 5ms/step\n",
            "Epoch 43/100\n",
            "844/844 - 5s - loss: 0.1376 - accuracy: 0.9602 - val_loss: 0.1379 - val_accuracy: 0.9612 - 5s/epoch - 5ms/step\n",
            "Epoch 44/100\n",
            "844/844 - 5s - loss: 0.1353 - accuracy: 0.9603 - val_loss: 0.1364 - val_accuracy: 0.9610 - 5s/epoch - 6ms/step\n",
            "Epoch 45/100\n",
            "844/844 - 5s - loss: 0.1332 - accuracy: 0.9613 - val_loss: 0.1338 - val_accuracy: 0.9627 - 5s/epoch - 5ms/step\n",
            "Epoch 46/100\n",
            "844/844 - 5s - loss: 0.1310 - accuracy: 0.9620 - val_loss: 0.1319 - val_accuracy: 0.9635 - 5s/epoch - 6ms/step\n",
            "Epoch 47/100\n",
            "844/844 - 5s - loss: 0.1290 - accuracy: 0.9629 - val_loss: 0.1299 - val_accuracy: 0.9625 - 5s/epoch - 6ms/step\n",
            "Epoch 48/100\n",
            "844/844 - 5s - loss: 0.1269 - accuracy: 0.9634 - val_loss: 0.1290 - val_accuracy: 0.9637 - 5s/epoch - 6ms/step\n",
            "Epoch 49/100\n",
            "844/844 - 5s - loss: 0.1251 - accuracy: 0.9641 - val_loss: 0.1283 - val_accuracy: 0.9647 - 5s/epoch - 5ms/step\n",
            "Epoch 50/100\n",
            "844/844 - 5s - loss: 0.1230 - accuracy: 0.9645 - val_loss: 0.1270 - val_accuracy: 0.9647 - 5s/epoch - 6ms/step\n",
            "Epoch 51/100\n",
            "844/844 - 5s - loss: 0.1212 - accuracy: 0.9649 - val_loss: 0.1236 - val_accuracy: 0.9660 - 5s/epoch - 6ms/step\n",
            "Epoch 52/100\n",
            "844/844 - 5s - loss: 0.1194 - accuracy: 0.9658 - val_loss: 0.1215 - val_accuracy: 0.9665 - 5s/epoch - 6ms/step\n",
            "Epoch 53/100\n",
            "844/844 - 5s - loss: 0.1177 - accuracy: 0.9659 - val_loss: 0.1212 - val_accuracy: 0.9668 - 5s/epoch - 5ms/step\n",
            "Epoch 54/100\n",
            "844/844 - 5s - loss: 0.1160 - accuracy: 0.9669 - val_loss: 0.1200 - val_accuracy: 0.9677 - 5s/epoch - 6ms/step\n",
            "Epoch 55/100\n",
            "844/844 - 5s - loss: 0.1141 - accuracy: 0.9671 - val_loss: 0.1189 - val_accuracy: 0.9678 - 5s/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "844/844 - 4s - loss: 0.1126 - accuracy: 0.9676 - val_loss: 0.1177 - val_accuracy: 0.9672 - 4s/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "844/844 - 4s - loss: 0.1111 - accuracy: 0.9681 - val_loss: 0.1155 - val_accuracy: 0.9682 - 4s/epoch - 5ms/step\n",
            "Epoch 58/100\n",
            "844/844 - 4s - loss: 0.1095 - accuracy: 0.9687 - val_loss: 0.1144 - val_accuracy: 0.9698 - 4s/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "844/844 - 5s - loss: 0.1079 - accuracy: 0.9689 - val_loss: 0.1132 - val_accuracy: 0.9687 - 5s/epoch - 6ms/step\n",
            "Epoch 60/100\n",
            "844/844 - 5s - loss: 0.1064 - accuracy: 0.9693 - val_loss: 0.1134 - val_accuracy: 0.9682 - 5s/epoch - 6ms/step\n",
            "Epoch 61/100\n",
            "844/844 - 5s - loss: 0.1051 - accuracy: 0.9697 - val_loss: 0.1107 - val_accuracy: 0.9688 - 5s/epoch - 5ms/step\n",
            "Epoch 62/100\n",
            "844/844 - 5s - loss: 0.1037 - accuracy: 0.9701 - val_loss: 0.1104 - val_accuracy: 0.9707 - 5s/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "844/844 - 5s - loss: 0.1022 - accuracy: 0.9707 - val_loss: 0.1095 - val_accuracy: 0.9693 - 5s/epoch - 6ms/step\n",
            "Epoch 64/100\n",
            "844/844 - 4s - loss: 0.1008 - accuracy: 0.9710 - val_loss: 0.1088 - val_accuracy: 0.9697 - 4s/epoch - 5ms/step\n",
            "Epoch 65/100\n",
            "844/844 - 5s - loss: 0.0997 - accuracy: 0.9713 - val_loss: 0.1078 - val_accuracy: 0.9697 - 5s/epoch - 6ms/step\n",
            "Epoch 66/100\n",
            "844/844 - 4s - loss: 0.0981 - accuracy: 0.9716 - val_loss: 0.1066 - val_accuracy: 0.9708 - 4s/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "844/844 - 5s - loss: 0.0970 - accuracy: 0.9722 - val_loss: 0.1053 - val_accuracy: 0.9702 - 5s/epoch - 6ms/step\n",
            "Epoch 68/100\n",
            "844/844 - 5s - loss: 0.0960 - accuracy: 0.9722 - val_loss: 0.1050 - val_accuracy: 0.9697 - 5s/epoch - 6ms/step\n",
            "Epoch 69/100\n",
            "844/844 - 5s - loss: 0.0945 - accuracy: 0.9728 - val_loss: 0.1023 - val_accuracy: 0.9703 - 5s/epoch - 6ms/step\n",
            "Epoch 70/100\n",
            "844/844 - 5s - loss: 0.0935 - accuracy: 0.9732 - val_loss: 0.1024 - val_accuracy: 0.9708 - 5s/epoch - 6ms/step\n",
            "Epoch 71/100\n",
            "844/844 - 5s - loss: 0.0924 - accuracy: 0.9735 - val_loss: 0.1017 - val_accuracy: 0.9715 - 5s/epoch - 6ms/step\n",
            "Epoch 72/100\n",
            "844/844 - 4s - loss: 0.0912 - accuracy: 0.9739 - val_loss: 0.0995 - val_accuracy: 0.9718 - 4s/epoch - 5ms/step\n",
            "Epoch 73/100\n",
            "844/844 - 4s - loss: 0.0901 - accuracy: 0.9743 - val_loss: 0.0998 - val_accuracy: 0.9713 - 4s/epoch - 5ms/step\n",
            "Epoch 74/100\n",
            "844/844 - 4s - loss: 0.0890 - accuracy: 0.9746 - val_loss: 0.0996 - val_accuracy: 0.9717 - 4s/epoch - 5ms/step\n",
            "Epoch 75/100\n",
            "844/844 - 4s - loss: 0.0879 - accuracy: 0.9747 - val_loss: 0.0973 - val_accuracy: 0.9723 - 4s/epoch - 5ms/step\n",
            "Epoch 76/100\n",
            "844/844 - 5s - loss: 0.0868 - accuracy: 0.9749 - val_loss: 0.0980 - val_accuracy: 0.9717 - 5s/epoch - 6ms/step\n",
            "Epoch 77/100\n",
            "844/844 - 5s - loss: 0.0858 - accuracy: 0.9750 - val_loss: 0.0961 - val_accuracy: 0.9728 - 5s/epoch - 6ms/step\n",
            "Epoch 78/100\n",
            "844/844 - 5s - loss: 0.0850 - accuracy: 0.9753 - val_loss: 0.0957 - val_accuracy: 0.9733 - 5s/epoch - 6ms/step\n",
            "Epoch 79/100\n",
            "844/844 - 5s - loss: 0.0840 - accuracy: 0.9757 - val_loss: 0.0966 - val_accuracy: 0.9723 - 5s/epoch - 6ms/step\n",
            "Epoch 80/100\n",
            "844/844 - 4s - loss: 0.0830 - accuracy: 0.9757 - val_loss: 0.0942 - val_accuracy: 0.9723 - 4s/epoch - 5ms/step\n",
            "Epoch 81/100\n",
            "844/844 - 4s - loss: 0.0820 - accuracy: 0.9765 - val_loss: 0.0926 - val_accuracy: 0.9742 - 4s/epoch - 5ms/step\n",
            "Epoch 82/100\n",
            "844/844 - 4s - loss: 0.0811 - accuracy: 0.9763 - val_loss: 0.0921 - val_accuracy: 0.9735 - 4s/epoch - 5ms/step\n",
            "Epoch 83/100\n",
            "844/844 - 4s - loss: 0.0802 - accuracy: 0.9767 - val_loss: 0.0916 - val_accuracy: 0.9730 - 4s/epoch - 5ms/step\n",
            "Epoch 84/100\n",
            "844/844 - 5s - loss: 0.0793 - accuracy: 0.9771 - val_loss: 0.0914 - val_accuracy: 0.9730 - 5s/epoch - 6ms/step\n",
            "Epoch 85/100\n",
            "844/844 - 5s - loss: 0.0784 - accuracy: 0.9774 - val_loss: 0.0914 - val_accuracy: 0.9747 - 5s/epoch - 5ms/step\n",
            "Epoch 86/100\n",
            "844/844 - 4s - loss: 0.0777 - accuracy: 0.9779 - val_loss: 0.0903 - val_accuracy: 0.9747 - 4s/epoch - 5ms/step\n",
            "Epoch 87/100\n",
            "844/844 - 4s - loss: 0.0768 - accuracy: 0.9780 - val_loss: 0.0891 - val_accuracy: 0.9755 - 4s/epoch - 5ms/step\n",
            "Epoch 88/100\n",
            "844/844 - 4s - loss: 0.0760 - accuracy: 0.9780 - val_loss: 0.0888 - val_accuracy: 0.9750 - 4s/epoch - 5ms/step\n",
            "Epoch 89/100\n",
            "844/844 - 5s - loss: 0.0752 - accuracy: 0.9780 - val_loss: 0.0889 - val_accuracy: 0.9753 - 5s/epoch - 6ms/step\n",
            "Epoch 90/100\n",
            "844/844 - 5s - loss: 0.0743 - accuracy: 0.9783 - val_loss: 0.0892 - val_accuracy: 0.9745 - 5s/epoch - 6ms/step\n",
            "Epoch 91/100\n",
            "844/844 - 4s - loss: 0.0735 - accuracy: 0.9786 - val_loss: 0.0890 - val_accuracy: 0.9748 - 4s/epoch - 5ms/step\n",
            "Epoch 92/100\n",
            "844/844 - 5s - loss: 0.0729 - accuracy: 0.9789 - val_loss: 0.0866 - val_accuracy: 0.9757 - 5s/epoch - 6ms/step\n",
            "Epoch 93/100\n",
            "844/844 - 5s - loss: 0.0721 - accuracy: 0.9794 - val_loss: 0.0871 - val_accuracy: 0.9752 - 5s/epoch - 6ms/step\n",
            "Epoch 94/100\n",
            "844/844 - 4s - loss: 0.0714 - accuracy: 0.9795 - val_loss: 0.0858 - val_accuracy: 0.9753 - 4s/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "844/844 - 5s - loss: 0.0706 - accuracy: 0.9794 - val_loss: 0.0859 - val_accuracy: 0.9747 - 5s/epoch - 6ms/step\n",
            "Epoch 96/100\n",
            "844/844 - 4s - loss: 0.0699 - accuracy: 0.9801 - val_loss: 0.0855 - val_accuracy: 0.9753 - 4s/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "844/844 - 5s - loss: 0.0692 - accuracy: 0.9802 - val_loss: 0.0847 - val_accuracy: 0.9755 - 5s/epoch - 6ms/step\n",
            "Epoch 98/100\n",
            "844/844 - 5s - loss: 0.0685 - accuracy: 0.9803 - val_loss: 0.0836 - val_accuracy: 0.9752 - 5s/epoch - 6ms/step\n",
            "Epoch 99/100\n",
            "844/844 - 5s - loss: 0.0677 - accuracy: 0.9809 - val_loss: 0.0833 - val_accuracy: 0.9770 - 5s/epoch - 6ms/step\n",
            "Epoch 100/100\n",
            "844/844 - 5s - loss: 0.0671 - accuracy: 0.9806 - val_loss: 0.0821 - val_accuracy: 0.9752 - 5s/epoch - 6ms/step\n",
            "evaluation start!\n",
            "157/157 - 1s - loss: 0.0808 - accuracy: 0.9739 - 725ms/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deeper CNN\n",
        "\n",
        "What if we go deeper with CNN layers?"
      ],
      "metadata": {
        "id": "OsAd-h25-gx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Deeper_CNN_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    \n",
        "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256, activation = \"relu\"),\n",
        "    keras.layers.Dense(128, activation = \"relu\"),\n",
        "    keras.layers.Dense(10, activation = \"softmax\"),\n",
        "])\n",
        "\n",
        "Deeper_CNN_model.summary()\n",
        "Deeper_CNN_model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
        "\n",
        "with tf.device(device_name = device_name):\n",
        "    print(\"training start!\")\n",
        "    hist = Deeper_CNN_model.fit(x_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, shuffle = True, verbose = 2, validation_data=(x_val, y_val))\n",
        "    print(\"evaluation start!\")\n",
        "    Deeper_CNN_model.evaluate(x_test, y_test, batch_size = BATCH_SIZE, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oTXnaD2-iNr",
        "outputId": "0a8df057-9aa4-4dd0-e22f-fcba0df06b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 3, 3, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 1, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 159,882\n",
            "Trainable params: 159,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "training start!\n",
            "Epoch 1/100\n",
            "844/844 - 7s - loss: 2.2968 - accuracy: 0.1884 - val_loss: 2.2884 - val_accuracy: 0.2282 - 7s/epoch - 9ms/step\n",
            "Epoch 2/100\n",
            "844/844 - 6s - loss: 2.2780 - accuracy: 0.2637 - val_loss: 2.2675 - val_accuracy: 0.3078 - 6s/epoch - 7ms/step\n",
            "Epoch 3/100\n",
            "844/844 - 6s - loss: 2.2511 - accuracy: 0.3393 - val_loss: 2.2325 - val_accuracy: 0.3722 - 6s/epoch - 7ms/step\n",
            "Epoch 4/100\n",
            "844/844 - 6s - loss: 2.1966 - accuracy: 0.4350 - val_loss: 2.1506 - val_accuracy: 0.5238 - 6s/epoch - 7ms/step\n",
            "Epoch 5/100\n",
            "844/844 - 6s - loss: 2.0415 - accuracy: 0.5842 - val_loss: 1.8822 - val_accuracy: 0.6298 - 6s/epoch - 7ms/step\n",
            "Epoch 6/100\n",
            "844/844 - 6s - loss: 1.5455 - accuracy: 0.6829 - val_loss: 1.1778 - val_accuracy: 0.7368 - 6s/epoch - 7ms/step\n",
            "Epoch 7/100\n",
            "844/844 - 6s - loss: 0.9104 - accuracy: 0.7804 - val_loss: 0.7168 - val_accuracy: 0.8167 - 6s/epoch - 7ms/step\n",
            "Epoch 8/100\n",
            "844/844 - 6s - loss: 0.6176 - accuracy: 0.8351 - val_loss: 0.5265 - val_accuracy: 0.8558 - 6s/epoch - 7ms/step\n",
            "Epoch 9/100\n",
            "844/844 - 6s - loss: 0.4845 - accuracy: 0.8647 - val_loss: 0.4266 - val_accuracy: 0.8782 - 6s/epoch - 7ms/step\n",
            "Epoch 10/100\n",
            "844/844 - 6s - loss: 0.4071 - accuracy: 0.8833 - val_loss: 0.3721 - val_accuracy: 0.8915 - 6s/epoch - 7ms/step\n",
            "Epoch 11/100\n",
            "844/844 - 6s - loss: 0.3562 - accuracy: 0.8957 - val_loss: 0.3230 - val_accuracy: 0.9005 - 6s/epoch - 7ms/step\n",
            "Epoch 12/100\n",
            "844/844 - 6s - loss: 0.3194 - accuracy: 0.9048 - val_loss: 0.2922 - val_accuracy: 0.9127 - 6s/epoch - 7ms/step\n",
            "Epoch 13/100\n",
            "844/844 - 6s - loss: 0.2908 - accuracy: 0.9119 - val_loss: 0.2721 - val_accuracy: 0.9167 - 6s/epoch - 7ms/step\n",
            "Epoch 14/100\n",
            "844/844 - 6s - loss: 0.2677 - accuracy: 0.9192 - val_loss: 0.2453 - val_accuracy: 0.9250 - 6s/epoch - 7ms/step\n",
            "Epoch 15/100\n",
            "844/844 - 6s - loss: 0.2491 - accuracy: 0.9248 - val_loss: 0.2278 - val_accuracy: 0.9322 - 6s/epoch - 7ms/step\n",
            "Epoch 16/100\n",
            "844/844 - 6s - loss: 0.2332 - accuracy: 0.9294 - val_loss: 0.2175 - val_accuracy: 0.9348 - 6s/epoch - 7ms/step\n",
            "Epoch 17/100\n",
            "844/844 - 6s - loss: 0.2199 - accuracy: 0.9326 - val_loss: 0.2023 - val_accuracy: 0.9388 - 6s/epoch - 7ms/step\n",
            "Epoch 18/100\n",
            "844/844 - 6s - loss: 0.2086 - accuracy: 0.9368 - val_loss: 0.1957 - val_accuracy: 0.9405 - 6s/epoch - 7ms/step\n",
            "Epoch 19/100\n",
            "844/844 - 6s - loss: 0.1989 - accuracy: 0.9397 - val_loss: 0.1866 - val_accuracy: 0.9443 - 6s/epoch - 7ms/step\n",
            "Epoch 20/100\n",
            "844/844 - 6s - loss: 0.1894 - accuracy: 0.9418 - val_loss: 0.1783 - val_accuracy: 0.9470 - 6s/epoch - 7ms/step\n",
            "Epoch 21/100\n",
            "844/844 - 6s - loss: 0.1816 - accuracy: 0.9447 - val_loss: 0.1734 - val_accuracy: 0.9492 - 6s/epoch - 7ms/step\n",
            "Epoch 22/100\n",
            "844/844 - 6s - loss: 0.1744 - accuracy: 0.9466 - val_loss: 0.1637 - val_accuracy: 0.9515 - 6s/epoch - 7ms/step\n",
            "Epoch 23/100\n",
            "844/844 - 6s - loss: 0.1687 - accuracy: 0.9488 - val_loss: 0.1611 - val_accuracy: 0.9515 - 6s/epoch - 7ms/step\n",
            "Epoch 24/100\n",
            "844/844 - 6s - loss: 0.1626 - accuracy: 0.9500 - val_loss: 0.1590 - val_accuracy: 0.9517 - 6s/epoch - 7ms/step\n",
            "Epoch 25/100\n",
            "844/844 - 6s - loss: 0.1570 - accuracy: 0.9515 - val_loss: 0.1527 - val_accuracy: 0.9538 - 6s/epoch - 7ms/step\n",
            "Epoch 26/100\n",
            "844/844 - 6s - loss: 0.1525 - accuracy: 0.9536 - val_loss: 0.1465 - val_accuracy: 0.9557 - 6s/epoch - 7ms/step\n",
            "Epoch 27/100\n",
            "844/844 - 6s - loss: 0.1481 - accuracy: 0.9553 - val_loss: 0.1445 - val_accuracy: 0.9550 - 6s/epoch - 7ms/step\n",
            "Epoch 28/100\n",
            "844/844 - 6s - loss: 0.1435 - accuracy: 0.9561 - val_loss: 0.1413 - val_accuracy: 0.9578 - 6s/epoch - 7ms/step\n",
            "Epoch 29/100\n",
            "844/844 - 6s - loss: 0.1400 - accuracy: 0.9572 - val_loss: 0.1351 - val_accuracy: 0.9582 - 6s/epoch - 7ms/step\n",
            "Epoch 30/100\n",
            "844/844 - 6s - loss: 0.1357 - accuracy: 0.9587 - val_loss: 0.1337 - val_accuracy: 0.9587 - 6s/epoch - 7ms/step\n",
            "Epoch 31/100\n",
            "844/844 - 6s - loss: 0.1326 - accuracy: 0.9587 - val_loss: 0.1311 - val_accuracy: 0.9607 - 6s/epoch - 7ms/step\n",
            "Epoch 32/100\n",
            "844/844 - 6s - loss: 0.1297 - accuracy: 0.9607 - val_loss: 0.1323 - val_accuracy: 0.9622 - 6s/epoch - 7ms/step\n",
            "Epoch 33/100\n",
            "844/844 - 6s - loss: 0.1264 - accuracy: 0.9610 - val_loss: 0.1269 - val_accuracy: 0.9610 - 6s/epoch - 7ms/step\n",
            "Epoch 34/100\n",
            "844/844 - 6s - loss: 0.1235 - accuracy: 0.9620 - val_loss: 0.1229 - val_accuracy: 0.9638 - 6s/epoch - 7ms/step\n",
            "Epoch 35/100\n",
            "844/844 - 6s - loss: 0.1212 - accuracy: 0.9631 - val_loss: 0.1206 - val_accuracy: 0.9620 - 6s/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "844/844 - 6s - loss: 0.1187 - accuracy: 0.9630 - val_loss: 0.1237 - val_accuracy: 0.9623 - 6s/epoch - 7ms/step\n",
            "Epoch 37/100\n",
            "844/844 - 6s - loss: 0.1164 - accuracy: 0.9648 - val_loss: 0.1230 - val_accuracy: 0.9638 - 6s/epoch - 7ms/step\n",
            "Epoch 38/100\n",
            "844/844 - 6s - loss: 0.1134 - accuracy: 0.9657 - val_loss: 0.1174 - val_accuracy: 0.9627 - 6s/epoch - 7ms/step\n",
            "Epoch 39/100\n",
            "844/844 - 6s - loss: 0.1115 - accuracy: 0.9654 - val_loss: 0.1144 - val_accuracy: 0.9648 - 6s/epoch - 7ms/step\n",
            "Epoch 40/100\n",
            "844/844 - 6s - loss: 0.1096 - accuracy: 0.9669 - val_loss: 0.1091 - val_accuracy: 0.9678 - 6s/epoch - 7ms/step\n",
            "Epoch 41/100\n",
            "844/844 - 6s - loss: 0.1078 - accuracy: 0.9674 - val_loss: 0.1136 - val_accuracy: 0.9653 - 6s/epoch - 7ms/step\n",
            "Epoch 42/100\n",
            "844/844 - 6s - loss: 0.1052 - accuracy: 0.9680 - val_loss: 0.1117 - val_accuracy: 0.9672 - 6s/epoch - 7ms/step\n",
            "Epoch 43/100\n",
            "844/844 - 6s - loss: 0.1034 - accuracy: 0.9678 - val_loss: 0.1086 - val_accuracy: 0.9682 - 6s/epoch - 7ms/step\n",
            "Epoch 44/100\n",
            "844/844 - 6s - loss: 0.1020 - accuracy: 0.9689 - val_loss: 0.1026 - val_accuracy: 0.9695 - 6s/epoch - 7ms/step\n",
            "Epoch 45/100\n",
            "844/844 - 6s - loss: 0.1004 - accuracy: 0.9699 - val_loss: 0.1065 - val_accuracy: 0.9662 - 6s/epoch - 7ms/step\n",
            "Epoch 46/100\n",
            "844/844 - 6s - loss: 0.0987 - accuracy: 0.9698 - val_loss: 0.1030 - val_accuracy: 0.9702 - 6s/epoch - 7ms/step\n",
            "Epoch 47/100\n",
            "844/844 - 6s - loss: 0.0973 - accuracy: 0.9704 - val_loss: 0.1001 - val_accuracy: 0.9702 - 6s/epoch - 7ms/step\n",
            "Epoch 48/100\n",
            "844/844 - 6s - loss: 0.0958 - accuracy: 0.9704 - val_loss: 0.0997 - val_accuracy: 0.9712 - 6s/epoch - 7ms/step\n",
            "Epoch 49/100\n",
            "844/844 - 6s - loss: 0.0939 - accuracy: 0.9722 - val_loss: 0.1054 - val_accuracy: 0.9682 - 6s/epoch - 7ms/step\n",
            "Epoch 50/100\n",
            "844/844 - 6s - loss: 0.0925 - accuracy: 0.9716 - val_loss: 0.0983 - val_accuracy: 0.9702 - 6s/epoch - 7ms/step\n",
            "Epoch 51/100\n",
            "844/844 - 6s - loss: 0.0910 - accuracy: 0.9727 - val_loss: 0.0961 - val_accuracy: 0.9723 - 6s/epoch - 7ms/step\n",
            "Epoch 52/100\n",
            "844/844 - 6s - loss: 0.0902 - accuracy: 0.9730 - val_loss: 0.0965 - val_accuracy: 0.9722 - 6s/epoch - 7ms/step\n",
            "Epoch 53/100\n",
            "844/844 - 6s - loss: 0.0889 - accuracy: 0.9733 - val_loss: 0.1022 - val_accuracy: 0.9692 - 6s/epoch - 7ms/step\n",
            "Epoch 54/100\n",
            "844/844 - 6s - loss: 0.0875 - accuracy: 0.9733 - val_loss: 0.0964 - val_accuracy: 0.9707 - 6s/epoch - 7ms/step\n",
            "Epoch 55/100\n",
            "844/844 - 6s - loss: 0.0858 - accuracy: 0.9737 - val_loss: 0.0933 - val_accuracy: 0.9732 - 6s/epoch - 7ms/step\n",
            "Epoch 56/100\n",
            "844/844 - 6s - loss: 0.0852 - accuracy: 0.9744 - val_loss: 0.0921 - val_accuracy: 0.9723 - 6s/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "844/844 - 5s - loss: 0.0837 - accuracy: 0.9748 - val_loss: 0.0906 - val_accuracy: 0.9723 - 5s/epoch - 7ms/step\n",
            "Epoch 58/100\n",
            "844/844 - 6s - loss: 0.0830 - accuracy: 0.9746 - val_loss: 0.0946 - val_accuracy: 0.9728 - 6s/epoch - 7ms/step\n",
            "Epoch 59/100\n",
            "844/844 - 6s - loss: 0.0818 - accuracy: 0.9752 - val_loss: 0.0935 - val_accuracy: 0.9720 - 6s/epoch - 7ms/step\n",
            "Epoch 60/100\n",
            "844/844 - 6s - loss: 0.0806 - accuracy: 0.9756 - val_loss: 0.0868 - val_accuracy: 0.9740 - 6s/epoch - 7ms/step\n",
            "Epoch 61/100\n",
            "844/844 - 6s - loss: 0.0795 - accuracy: 0.9763 - val_loss: 0.0879 - val_accuracy: 0.9737 - 6s/epoch - 7ms/step\n",
            "Epoch 62/100\n",
            "844/844 - 6s - loss: 0.0787 - accuracy: 0.9763 - val_loss: 0.0938 - val_accuracy: 0.9712 - 6s/epoch - 7ms/step\n",
            "Epoch 63/100\n",
            "844/844 - 6s - loss: 0.0780 - accuracy: 0.9769 - val_loss: 0.0905 - val_accuracy: 0.9717 - 6s/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "844/844 - 6s - loss: 0.0767 - accuracy: 0.9766 - val_loss: 0.0892 - val_accuracy: 0.9720 - 6s/epoch - 7ms/step\n",
            "Epoch 65/100\n",
            "844/844 - 6s - loss: 0.0760 - accuracy: 0.9771 - val_loss: 0.0837 - val_accuracy: 0.9748 - 6s/epoch - 7ms/step\n",
            "Epoch 66/100\n",
            "844/844 - 6s - loss: 0.0748 - accuracy: 0.9779 - val_loss: 0.0834 - val_accuracy: 0.9738 - 6s/epoch - 7ms/step\n",
            "Epoch 67/100\n",
            "844/844 - 6s - loss: 0.0742 - accuracy: 0.9777 - val_loss: 0.0859 - val_accuracy: 0.9727 - 6s/epoch - 7ms/step\n",
            "Epoch 68/100\n",
            "844/844 - 6s - loss: 0.0728 - accuracy: 0.9784 - val_loss: 0.0983 - val_accuracy: 0.9705 - 6s/epoch - 7ms/step\n",
            "Epoch 69/100\n",
            "844/844 - 6s - loss: 0.0727 - accuracy: 0.9782 - val_loss: 0.0851 - val_accuracy: 0.9743 - 6s/epoch - 7ms/step\n",
            "Epoch 70/100\n",
            "844/844 - 6s - loss: 0.0714 - accuracy: 0.9790 - val_loss: 0.0829 - val_accuracy: 0.9753 - 6s/epoch - 7ms/step\n",
            "Epoch 71/100\n",
            "844/844 - 6s - loss: 0.0708 - accuracy: 0.9783 - val_loss: 0.0955 - val_accuracy: 0.9718 - 6s/epoch - 7ms/step\n",
            "Epoch 72/100\n",
            "844/844 - 6s - loss: 0.0698 - accuracy: 0.9789 - val_loss: 0.0887 - val_accuracy: 0.9730 - 6s/epoch - 7ms/step\n",
            "Epoch 73/100\n",
            "844/844 - 6s - loss: 0.0692 - accuracy: 0.9792 - val_loss: 0.0849 - val_accuracy: 0.9740 - 6s/epoch - 7ms/step\n",
            "Epoch 74/100\n",
            "844/844 - 6s - loss: 0.0683 - accuracy: 0.9797 - val_loss: 0.0868 - val_accuracy: 0.9745 - 6s/epoch - 7ms/step\n",
            "Epoch 75/100\n",
            "844/844 - 6s - loss: 0.0680 - accuracy: 0.9794 - val_loss: 0.0810 - val_accuracy: 0.9755 - 6s/epoch - 7ms/step\n",
            "Epoch 76/100\n",
            "844/844 - 6s - loss: 0.0674 - accuracy: 0.9797 - val_loss: 0.0846 - val_accuracy: 0.9737 - 6s/epoch - 7ms/step\n",
            "Epoch 77/100\n",
            "844/844 - 6s - loss: 0.0667 - accuracy: 0.9793 - val_loss: 0.0830 - val_accuracy: 0.9742 - 6s/epoch - 7ms/step\n",
            "Epoch 78/100\n",
            "844/844 - 6s - loss: 0.0659 - accuracy: 0.9803 - val_loss: 0.0792 - val_accuracy: 0.9758 - 6s/epoch - 7ms/step\n",
            "Epoch 79/100\n",
            "844/844 - 6s - loss: 0.0652 - accuracy: 0.9805 - val_loss: 0.0793 - val_accuracy: 0.9762 - 6s/epoch - 7ms/step\n",
            "Epoch 80/100\n",
            "844/844 - 6s - loss: 0.0643 - accuracy: 0.9810 - val_loss: 0.0858 - val_accuracy: 0.9743 - 6s/epoch - 7ms/step\n",
            "Epoch 81/100\n",
            "844/844 - 6s - loss: 0.0639 - accuracy: 0.9810 - val_loss: 0.0770 - val_accuracy: 0.9758 - 6s/epoch - 7ms/step\n",
            "Epoch 82/100\n",
            "844/844 - 6s - loss: 0.0632 - accuracy: 0.9812 - val_loss: 0.0804 - val_accuracy: 0.9745 - 6s/epoch - 7ms/step\n",
            "Epoch 83/100\n",
            "844/844 - 6s - loss: 0.0622 - accuracy: 0.9815 - val_loss: 0.0762 - val_accuracy: 0.9752 - 6s/epoch - 7ms/step\n",
            "Epoch 84/100\n",
            "844/844 - 6s - loss: 0.0619 - accuracy: 0.9815 - val_loss: 0.0756 - val_accuracy: 0.9753 - 6s/epoch - 7ms/step\n",
            "Epoch 85/100\n",
            "844/844 - 6s - loss: 0.0610 - accuracy: 0.9817 - val_loss: 0.0750 - val_accuracy: 0.9753 - 6s/epoch - 7ms/step\n",
            "Epoch 86/100\n",
            "844/844 - 6s - loss: 0.0602 - accuracy: 0.9819 - val_loss: 0.0857 - val_accuracy: 0.9730 - 6s/epoch - 7ms/step\n",
            "Epoch 87/100\n",
            "844/844 - 6s - loss: 0.0600 - accuracy: 0.9823 - val_loss: 0.0775 - val_accuracy: 0.9770 - 6s/epoch - 7ms/step\n",
            "Epoch 88/100\n",
            "844/844 - 6s - loss: 0.0595 - accuracy: 0.9825 - val_loss: 0.0759 - val_accuracy: 0.9777 - 6s/epoch - 7ms/step\n",
            "Epoch 89/100\n",
            "844/844 - 6s - loss: 0.0591 - accuracy: 0.9826 - val_loss: 0.0776 - val_accuracy: 0.9770 - 6s/epoch - 7ms/step\n",
            "Epoch 90/100\n",
            "844/844 - 6s - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.0779 - val_accuracy: 0.9752 - 6s/epoch - 7ms/step\n",
            "Epoch 91/100\n",
            "844/844 - 6s - loss: 0.0578 - accuracy: 0.9830 - val_loss: 0.0780 - val_accuracy: 0.9750 - 6s/epoch - 7ms/step\n",
            "Epoch 92/100\n",
            "844/844 - 6s - loss: 0.0575 - accuracy: 0.9832 - val_loss: 0.0821 - val_accuracy: 0.9758 - 6s/epoch - 7ms/step\n",
            "Epoch 93/100\n",
            "844/844 - 6s - loss: 0.0568 - accuracy: 0.9830 - val_loss: 0.0790 - val_accuracy: 0.9763 - 6s/epoch - 7ms/step\n",
            "Epoch 94/100\n",
            "844/844 - 6s - loss: 0.0564 - accuracy: 0.9832 - val_loss: 0.0741 - val_accuracy: 0.9767 - 6s/epoch - 7ms/step\n",
            "Epoch 95/100\n",
            "844/844 - 6s - loss: 0.0559 - accuracy: 0.9834 - val_loss: 0.0771 - val_accuracy: 0.9763 - 6s/epoch - 7ms/step\n",
            "Epoch 96/100\n",
            "844/844 - 6s - loss: 0.0554 - accuracy: 0.9834 - val_loss: 0.0725 - val_accuracy: 0.9772 - 6s/epoch - 7ms/step\n",
            "Epoch 97/100\n",
            "844/844 - 6s - loss: 0.0544 - accuracy: 0.9837 - val_loss: 0.0760 - val_accuracy: 0.9775 - 6s/epoch - 7ms/step\n",
            "Epoch 98/100\n",
            "844/844 - 6s - loss: 0.0544 - accuracy: 0.9839 - val_loss: 0.0720 - val_accuracy: 0.9772 - 6s/epoch - 7ms/step\n",
            "Epoch 99/100\n",
            "844/844 - 6s - loss: 0.0540 - accuracy: 0.9844 - val_loss: 0.0770 - val_accuracy: 0.9770 - 6s/epoch - 7ms/step\n",
            "Epoch 100/100\n",
            "844/844 - 6s - loss: 0.0535 - accuracy: 0.9844 - val_loss: 0.0784 - val_accuracy: 0.9763 - 6s/epoch - 7ms/step\n",
            "evaluation start!\n",
            "157/157 - 1s - loss: 0.0749 - accuracy: 0.9781 - 612ms/epoch - 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deeper CNN with better Optimizer and Batchnorm\n",
        "\n",
        "Batchnorm was introduced to stablize the training process. Let's try them! Also, let's try with better optimizer, Adam."
      ],
      "metadata": {
        "id": "S3PBJayp-m5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam_optimizer = tf.optimizers.Adam(learning_rate=1e-03)"
      ],
      "metadata": {
        "id": "KvlW0NVL-mOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Deeper_CNN_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(32, (3, 3), padding = \"same\", input_shape=(28, 28, 1)),\n",
        "    keras.layers.Conv2D(32, (3, 3), padding = \"same\", input_shape=(28, 28, 1)),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    \n",
        "    keras.layers.Conv2D(64, (3, 3), padding = \"same\"),\n",
        "    keras.layers.Conv2D(64, (3, 3), padding = \"same\"),\n",
        "    keras.layers.ReLU(),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Conv2D(128, (3, 3), padding = \"same\"),\n",
        "    keras.layers.Conv2D(128, (3, 3), padding = \"same\"),\n",
        "    keras.layers.MaxPooling2D((2, 2)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(256),\n",
        "    keras.layers.Dense(128),\n",
        "    keras.layers.Dense(10),\n",
        "    keras.layers.Softmax()\n",
        "])\n",
        "\n",
        "Deeper_CNN_model.summary()\n",
        "Deeper_CNN_model.compile(loss = loss, optimizer = adam_optimizer, metrics = metrics)\n",
        "\n",
        "with tf.device(device_name = device_name):\n",
        "    print(\"training start!\")\n",
        "    hist = Deeper_CNN_model.fit(x_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, shuffle = True, verbose = 2, validation_data=(x_val, y_val))\n",
        "    print(\"evaluation start!\")\n",
        "    Deeper_CNN_model.evaluate(x_test, y_test, batch_size = BATCH_SIZE, verbose = 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aN5iS1f-q1y",
        "outputId": "78d74006-79aa-4a52-c5ff-c45ee410a9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 28, 32)        9248      \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 14, 14, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 7, 7, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 3, 3, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 3, 3, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1152)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               295168    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            " softmax (Softmax)           (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 616,682\n",
            "Trainable params: 616,234\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "training start!\n",
            "Epoch 1/100\n",
            "844/844 - 14s - loss: 0.1488 - accuracy: 0.9627 - val_loss: 0.0980 - val_accuracy: 0.9725 - 14s/epoch - 16ms/step\n",
            "Epoch 2/100\n",
            "844/844 - 12s - loss: 0.0660 - accuracy: 0.9817 - val_loss: 0.0855 - val_accuracy: 0.9763 - 12s/epoch - 14ms/step\n",
            "Epoch 3/100\n",
            "844/844 - 12s - loss: 0.0527 - accuracy: 0.9856 - val_loss: 0.0480 - val_accuracy: 0.9863 - 12s/epoch - 14ms/step\n",
            "Epoch 4/100\n",
            "844/844 - 12s - loss: 0.0430 - accuracy: 0.9874 - val_loss: 0.0474 - val_accuracy: 0.9880 - 12s/epoch - 14ms/step\n",
            "Epoch 5/100\n",
            "844/844 - 12s - loss: 0.0350 - accuracy: 0.9896 - val_loss: 0.0657 - val_accuracy: 0.9865 - 12s/epoch - 14ms/step\n",
            "Epoch 6/100\n",
            "844/844 - 12s - loss: 0.0327 - accuracy: 0.9905 - val_loss: 0.0531 - val_accuracy: 0.9852 - 12s/epoch - 14ms/step\n",
            "Epoch 7/100\n",
            "844/844 - 12s - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.0529 - val_accuracy: 0.9862 - 12s/epoch - 14ms/step\n",
            "Epoch 8/100\n",
            "844/844 - 12s - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.0611 - val_accuracy: 0.9837 - 12s/epoch - 14ms/step\n",
            "Epoch 9/100\n",
            "844/844 - 12s - loss: 0.0215 - accuracy: 0.9934 - val_loss: 0.0431 - val_accuracy: 0.9890 - 12s/epoch - 14ms/step\n",
            "Epoch 10/100\n",
            "844/844 - 12s - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0515 - val_accuracy: 0.9880 - 12s/epoch - 14ms/step\n",
            "Epoch 11/100\n",
            "844/844 - 12s - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0361 - val_accuracy: 0.9912 - 12s/epoch - 14ms/step\n",
            "Epoch 12/100\n"
          ]
        }
      ]
    }
  ]
}